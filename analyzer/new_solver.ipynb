{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "def load_set(directory):\n",
        "    try:\n",
        "        with open(f\"{directory}/texts.pkl\", \"rb\") as fp:\n",
        "            processed_texts = pickle.load(fp)\n",
        "        \n",
        "        with open(f\"{directory}/labels.pkl\", \"rb\") as fp:\n",
        "            labels = pickle.load(fp)\n",
        "    \n",
        "    except:\n",
        "        print(f'{directory} files not found. Please run the preprocess.ipynb before!')\n",
        "    \n",
        "    return processed_texts, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_texts, labels = load_set('train')\n",
        "val_processed_texts, val_labels = load_set('val')\n",
        "test_processed_texts, test_labels = load_set('test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeCAiBryYrB_"
      },
      "source": [
        "#### Tokenizing the posts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4ZVKC1AYrB_",
        "outputId": "633a4d17-5a49-4ccd-d758-ee9f1ccbec9f"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "nlp.pipe_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for doc in nlp.pipe([\"some text\", \"some other text\"]):\n",
        "#     print(doc._.trf_data.last_hidden_layer_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY_wzV2IYrB_",
        "outputId": "5c84949c-1826-4510-e0ad-7a5637f9d5eb"
      },
      "outputs": [],
      "source": [
        "doc = nlp('I was reading the paper.')\n",
        "print([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_set(set):\n",
        "    texts = set.copy()['text']\n",
        "    labels = set.copy()['class']\n",
        "    texts = [' '.join(text.split()[:500]) for text in texts]\n",
        "\n",
        "    docs = (doc for doc in (nlp.pipe(texts)))\n",
        "    processed_texts = []\n",
        "    for doc in docs:\n",
        "        lemmas = [token.lemma_ for token in doc if not token.is_stop]\n",
        "        processed_texts.append(' '.join(lemmas))\n",
        "    \n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return processed_texts, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(strat_train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_texts, labels = preprocess_set(strat_train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_val_texts, val_labels = preprocess_set(strat_val_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Creating the Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp_jIDKV3mm8"
      },
      "outputs": [],
      "source": [
        "# from keras_preprocessing.text import Tokenizer       # type: ignore\n",
        "\n",
        "# tokenizer = Tokenizer(num_words=3000, oov_token='<UNK>')\n",
        "# tokenizer.fit_on_texts(processed_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRx-PRv2YrB_"
      },
      "outputs": [],
      "source": [
        "# sequences = tokenizer.texts_to_sequences(processed_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01Q61iuTYrB_"
      },
      "outputs": [],
      "source": [
        "# sequence_lengths = [len(sequence) for sequence in sequences if len(sequence) < 1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmEb9aO4YrB_"
      },
      "outputs": [],
      "source": [
        "# plt.hist(sequence_lengths, bins=100, color='blue', align='left')\n",
        "# plt.xlabel('Sequence Length')\n",
        "# plt.ylabel('Number of Texts')\n",
        "# plt.title('Distribution of Sequence Lengths')\n",
        "# plt.xlim(0, 200)\n",
        "# plt.xticks(range(0, max(sequence_lengths) + 1, 100))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT8abyEzYrB_"
      },
      "outputs": [],
      "source": [
        "# from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# max_len=200\n",
        "\n",
        "# def get_sequences(tokenizer, texts):\n",
        "#     sequences = tokenizer.texts_to_sequences(texts)\n",
        "#     padded = pad_sequences(sequences, truncating='post', padding='post', maxlen=max_len)\n",
        "#     return padded\n",
        "\n",
        "# padded_train_seq = get_sequences(tokenizer, processed_texts)\n",
        "# train_labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOt3HsHuYrCA"
      },
      "outputs": [],
      "source": [
        "# word_index = tokenizer.word_index\n",
        "\n",
        "# sorted(word_index.items(), key=lambda x: x[1])[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knHAsJ6xYrCA"
      },
      "source": [
        "#### Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpiP2_ojYrCA"
      },
      "outputs": [],
      "source": [
        "Sequential = keras.models.Sequential\n",
        "\n",
        "model = Sequential([\n",
        "    keras.layers.TextVectorization(max_tokens=3000, output_sequence_length=3000),\n",
        "    keras.layers.Embedding(3000, 16),\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(20, return_sequences=True)),\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(20)),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "h = model.fit(\n",
        "    processed_texts, labels,\n",
        "    validation_data=(processed_val_texts, val_labels),\n",
        "    epochs=20,\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKDxcT0RYrCA"
      },
      "source": [
        "### Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVWJegdLYrCA"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xlqh_jPkYrCA"
      },
      "outputs": [],
      "source": [
        "processed_test_texts, test_labels = preprocess_set(strat_test_set)\n",
        "\n",
        "test_seq = get_sequences(tokenizer, processed_test_texts)\n",
        "test_labels = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cukopLkPYrCA"
      },
      "outputs": [],
      "source": [
        "test_seq, test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBWwAL6KYrCA"
      },
      "outputs": [],
      "source": [
        "_ = model.evaluate(test_seq, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-4q-qsTYrCB"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(test_seq)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "y_pred = np.array(list(map(lambda x: x[1], y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USN-oBMkYrCB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, y_pred).ravel()\n",
        "\n",
        "fpr = fp / (fp + tn)\n",
        "print(f\"False Positive Rate: {fpr:.4f}\")\n",
        "\n",
        "fnr = fn / (fn + tp)\n",
        "print(f\"False Negative Rate: {fnr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6B1GRA5VYrCB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(test_labels, y_pred, normalize=\"true\",\n",
        "                                        values_format=\".0%\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
