{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVexig9wYrB6"
      },
      "source": [
        "### Importing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GXeypmptYrB8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-08 18:20:47.805345: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-07-08 18:20:47.812265: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-08 18:20:47.822670: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-08 18:20:47.822690: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-08 18:20:47.829052: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-08 18:20:48.231784: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "\n",
        "posts = pd.read_csv(\"../data/Suicide_Detection.csv\")\n",
        "posts.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
        "posts[[\"class\"]] = (posts[[\"class\"]] == \"suicide\").astype(\"int16\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-08 18:20:49.445628: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-07-08 18:20:49.465103: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-07-08 18:20:49.465195: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryphGKPIYrB8"
      },
      "source": [
        "### Exploring the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4hWvkEXaYrB9",
        "outputId": "4629d5fc-7bb9-468d-a1e6-783ee8be37d1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Am I weird I don't get affected by compliments...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i need helpjust help me im crying so hard</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I’m so lostHello, my name is Adam (16) and I’v...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  class\n",
              "0  Ex Wife Threatening SuicideRecently I left my ...      1\n",
              "1  Am I weird I don't get affected by compliments...      0\n",
              "2  Finally 2020 is almost over... So I can never ...      0\n",
              "3          i need helpjust help me im crying so hard      1\n",
              "4  I’m so lostHello, my name is Adam (16) and I’v...      1"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "posts.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "sLghn4BmYrB9",
        "outputId": "96124882-00ef-41f3-aedf-99cd9c7129e6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>232074.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.500001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               class\n",
              "count  232074.000000\n",
              "mean        0.500000\n",
              "std         0.500001\n",
              "min         0.000000\n",
              "25%         0.000000\n",
              "50%         0.500000\n",
              "75%         1.000000\n",
              "max         1.000000"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "posts.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJBZk0iCYrB9"
      },
      "source": [
        "### Splitting the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Bg0p6FmCYrB9"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "strat_train_set, strat_test_set = train_test_split(posts, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yk4MC_4YrB9"
      },
      "source": [
        "#### Analyzing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iJDyF2hLYrB-",
        "outputId": "8b40935b-2d6c-4374-b5f1-12d763020b84"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>103752</th>\n",
              "      <td>I am going to kill myself soonI don't know whe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208014</th>\n",
              "      <td>Using this sub as a diary day 68 Today was gre...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220765</th>\n",
              "      <td>What else are you supposed to do?I've got a se...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116840</th>\n",
              "      <td>Hey you. Yes you I need your help to get this ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149067</th>\n",
              "      <td>non trans gender dysphoria be like menstruatio...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  class\n",
              "103752  I am going to kill myself soonI don't know whe...      1\n",
              "208014  Using this sub as a diary day 68 Today was gre...      0\n",
              "220765  What else are you supposed to do?I've got a se...      1\n",
              "116840  Hey you. Yes you I need your help to get this ...      0\n",
              "149067  non trans gender dysphoria be like menstruatio...      0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "posts = strat_train_set.copy()\n",
        "posts.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FysKL3dwYrB-"
      },
      "outputs": [],
      "source": [
        "post_lengths = [len(post.split()) for post in posts[\"text\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDC30B5mYrB-",
        "outputId": "069eb1ca-206e-4d08-c257-8ad58d547760"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[98, 58, 273, 54, 109, 10, 166, 103, 43, 190]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "post_lengths[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "lmRQ8uoTYrB-",
        "outputId": "a9ace718-d543-4821-99c7-0aec21f7beae"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(post_lengths, bins=100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDHTf-pRYrB-"
      },
      "source": [
        "### Building the Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tetRLZLfYrB-"
      },
      "source": [
        "#### Spliting the dataset (again)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPwlqbqGYrB-",
        "outputId": "29cff7ff-9209-4ec5-e02d-584c35c54f64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(103752    I am going to kill myself soonI don't know whe...\n",
              " 208014    Using this sub as a diary day 68 Today was gre...\n",
              " 220765    What else are you supposed to do?I've got a se...\n",
              " 116840    Hey you. Yes you I need your help to get this ...\n",
              " 149067    non trans gender dysphoria be like menstruatio...\n",
              " Name: text, dtype: object,\n",
              " 103752    1\n",
              " 208014    0\n",
              " 220765    1\n",
              " 116840    0\n",
              " 149067    0\n",
              " Name: class, dtype: int16)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts = posts.copy()['text'][:150000]\n",
        "labels = posts.copy()['class'][:150000]\n",
        "texts[:5], labels[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeCAiBryYrB_"
      },
      "source": [
        "#### Tokenizing the posts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4ZVKC1AYrB_",
        "outputId": "633a4d17-5a49-4ccd-d758-ee9f1ccbec9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'attribute_ruler', 'lemmatizer']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "spacy.prefer_gpu()\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "nlp.pipe_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY_wzV2IYrB_",
        "outputId": "5c84949c-1826-4510-e0ad-7a5637f9d5eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['read', 'paper']\n"
          ]
        }
      ],
      "source": [
        "doc = nlp('I was reading the paper.')\n",
        "print([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "150000"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NuQlNf6vYrB_"
      },
      "outputs": [
        {
          "ename": "OutOfMemoryError",
          "evalue": "Out of memory allocating 52,615,680 bytes (allocated so far: 11,544,960,000 bytes).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/language.py:1618\u001b[0m, in \u001b[0;36mLanguage.pipe\u001b[0;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[0m\n\u001b[1;32m   1616\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pipe \u001b[38;5;129;01min\u001b[39;00m pipes:\n\u001b[1;32m   1617\u001b[0m         docs \u001b[38;5;241m=\u001b[39m pipe(docs)\n\u001b[0;32m-> 1618\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/util.py:1703\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[1;32m   1694\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1695\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeCallable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1700\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   1701\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1703\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1704\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1705\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1706\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/pipeline/pipe.pyx:55\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/util.py:1703\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[1;32m   1694\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1695\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeCallable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1700\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   1701\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1703\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1704\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1705\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1706\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/pipeline/pipe.pyx:55\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/util.py:1703\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[1;32m   1694\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1695\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeCallable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1700\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   1701\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1703\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1704\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1705\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1706\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/pipeline/trainable_pipe.pyx:73\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/util.py:1650\u001b[0m, in \u001b[0;36mminibatch\u001b[0;34m(items, size)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1649\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[0;32m-> 1650\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1652\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/util.py:1703\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[1;32m   1694\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1695\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeCallable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1700\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   1701\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1703\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1704\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1705\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1706\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/pipeline/trainable_pipe.pyx:79\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/util.py:1722\u001b[0m, in \u001b[0;36mraise_error\u001b[0;34m(proc_name, proc, docs, e)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_error\u001b[39m(proc_name, proc, docs, e):\n\u001b[0;32m-> 1722\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/pipeline/trainable_pipe.pyx:75\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.pipe\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/pipeline/tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc((\u001b[38;5;241m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[0;32m--> 126\u001b[0m tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/layers/with_array.py:42\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](Xseq, is_train)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], \u001b[43m_list_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/layers/with_array.py:77\u001b[0m, in \u001b[0;36m_list_forward\u001b[0;34m(model, Xs, is_train)\u001b[0m\n\u001b[1;32m     75\u001b[0m lengths \u001b[38;5;241m=\u001b[39m NUMPY_OPS\u001b[38;5;241m.\u001b[39masarray1i([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m Xs])\n\u001b[1;32m     76\u001b[0m Xf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(Xs, pad\u001b[38;5;241m=\u001b[39mpad)\n\u001b[0;32m---> 77\u001b[0m Yf, get_dXf \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYs: ListXd) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ListXd:\n\u001b[1;32m     80\u001b[0m     dYf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(dYs, pad\u001b[38;5;241m=\u001b[39mpad)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/layers/residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m d_output \u001b[38;5;241m+\u001b[39m dX\n\u001b[0;32m---> 41\u001b[0m Y, backprop_layer \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [X[i] \u001b[38;5;241m+\u001b[39m Y[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))], backprop\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/layers/expand_window.py:22\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _expand_window_ragged(model, X)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_expand_window_floats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/layers/expand_window.py:30\u001b[0m, in \u001b[0;36m_expand_window_floats\u001b[0;34m(model, X)\u001b[0m\n\u001b[1;32m     28\u001b[0m nW \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq2col\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/backends/cupy_ops.py:274\u001b[0m, in \u001b[0;36mCupyOps.seq2col\u001b[0;34m(self, seq, nW, lengths)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given an (M, N) sequence of vectors, return an (M, N*(nW*2+1)) sequence.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03mThe new sequence is constructed by concatenating nW preceding and succeeding\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03mvectors onto each column in the sequence, to extract a window of features.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seq\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    272\u001b[0m     lengths \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m lengths\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m ):\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_custom_kernels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq2col\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mseq2col(seq, nW, lengths\u001b[38;5;241m=\u001b[39mlengths)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/backends/_custom_kernels.py:357\u001b[0m, in \u001b[0;36mseq2col\u001b[0;34m(seq, nW, lengths, threads_per_block, num_blocks)\u001b[0m\n\u001b[1;32m    354\u001b[0m lengths \u001b[38;5;241m=\u001b[39m check_seq2col_lengths(lengths, B)\n\u001b[1;32m    355\u001b[0m nL \u001b[38;5;241m=\u001b[39m lengths\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43m_alloc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mI\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnF\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzeros\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seq\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m lengths\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m seq\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/backends/_custom_kernels.py:177\u001b[0m, in \u001b[0;36m_alloc\u001b[0;34m(shape, dtype, zeros)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_alloc\u001b[39m(shape, dtype, \u001b[38;5;241m*\u001b[39m, zeros: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m zeros:\n\u001b[0;32m--> 177\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcupy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cupy\u001b[38;5;241m.\u001b[39mempty(shape, dtype)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/cupy/_creation/basic.py:211\u001b[0m, in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, order)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mzeros\u001b[39m(shape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    197\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a new array of given shape and dtype, filled with zeros.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mcupy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     a\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mmemset_async(\u001b[38;5;241m0\u001b[39m, a\u001b[38;5;241m.\u001b[39mnbytes)\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
            "File \u001b[0;32mcupy/_core/core.pyx:132\u001b[0m, in \u001b[0;36mcupy._core.core.ndarray.__new__\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/_core/core.pyx:220\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base._init\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/cuda/memory.pyx:740\u001b[0m, in \u001b[0;36mcupy.cuda.memory.alloc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/cuda/memory.pyx:1426\u001b[0m, in \u001b[0;36mcupy.cuda.memory.MemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/cuda/memory.pyx:1447\u001b[0m, in \u001b[0;36mcupy.cuda.memory.MemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/cuda/memory.pyx:1118\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/cuda/memory.pyx:1139\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._malloc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/cuda/memory.pyx:1384\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._try_malloc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/cuda/memory.pyx:1387\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._try_malloc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: Out of memory allocating 52,615,680 bytes (allocated so far: 11,544,960,000 bytes)."
          ]
        }
      ],
      "source": [
        "docs = list(nlp.pipe(texts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uySH09WwYrB_"
      },
      "outputs": [],
      "source": [
        "processed_texts = []\n",
        "for doc in docs:\n",
        "    lemmas = [token.lemma_ for token in doc]\n",
        "    processed_texts.append(' '.join(lemmas))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp_jIDKV3mm8"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.text import Tokenizer       # type: ignore\n",
        "\n",
        "tokenizer = Tokenizer(num_words=3000, oov_token='<UNK>')\n",
        "tokenizer.fit_on_texts(processed_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yik6LKxiYrB_"
      },
      "outputs": [],
      "source": [
        "# from keras.layers import TextVectorization\n",
        "\n",
        "# vectorizer = TextVectorization(max_tokens=100, output_mode='count', sparse=True)\n",
        "# vectorizer.adapt(processed_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRx-PRv2YrB_"
      },
      "outputs": [],
      "source": [
        "sequences = tokenizer.texts_to_sequences(processed_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01Q61iuTYrB_"
      },
      "outputs": [],
      "source": [
        "sequence_lengths = [len(sequence) for sequence in sequences if len(sequence) < 1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmEb9aO4YrB_"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(sequence_lengths, bins=100, color='blue', align='left')\n",
        "plt.xlabel('Sequence Length')\n",
        "plt.ylabel('Number of Texts')\n",
        "plt.title('Distribution of Sequence Lengths')\n",
        "plt.xlim(0, 200)\n",
        "plt.xticks(range(0, max(sequence_lengths) + 1, 100))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT8abyEzYrB_"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_len=200\n",
        "\n",
        "def get_sequences(tokenizer, texts):\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "    padded = pad_sequences(sequences, truncating='post', padding='post', maxlen=max_len)\n",
        "    return padded\n",
        "\n",
        "padded_train_seq = get_sequences(tokenizer, processed_texts)\n",
        "train_labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOt3HsHuYrCA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('<UNK>', 1),\n",
              " ('i', 2),\n",
              " ('be', 3),\n",
              " ('to', 4),\n",
              " ('and', 5),\n",
              " ('the', 6),\n",
              " ('not', 7),\n",
              " ('a', 8),\n",
              " ('my', 9),\n",
              " ('do', 10)]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_index = tokenizer.word_index\n",
        "\n",
        "sorted(word_index.items(), key=lambda x: x[1])[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knHAsJ6xYrCA"
      },
      "source": [
        "#### Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('strat_train_set', 135788791),\n",
              " ('texts', 135510303),\n",
              " ('strat_val_set', 45058668),\n",
              " ('strat_test_set', 44984403),\n",
              " ('val_texts', 44965838),\n",
              " ('post_lengths', 1624056),\n",
              " ('labels', 1392472),\n",
              " ('docs', 1140568),\n",
              " ('processed_texts', 1140568),\n",
              " ('val_labels', 464182),\n",
              " ('lemmas', 7832),\n",
              " ('Tokenizer', 1704),\n",
              " ('doc', 184),\n",
              " ('open', 160),\n",
              " ('train_test_split', 160),\n",
              " ('np', 72),\n",
              " ('pd', 72),\n",
              " ('plt', 72),\n",
              " ('tf', 72),\n",
              " ('nlp', 48),\n",
              " ('tokenizer', 48)]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "# These are the usual ipython objects, including this one you are creating\n",
        "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
        "\n",
        "# Get a sorted list of the objects and their sizes\n",
        "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpiP2_ojYrCA"
      },
      "outputs": [],
      "source": [
        "Sequential = keras.models.Sequential\n",
        "\n",
        "model = Sequential([\n",
        "        keras.layers.Embedding(1000, 16),\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(20, return_sequences=True)),\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(20)),\n",
        "    keras.layers.Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHKM2N0BYrCA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   2,   61,  334, ...,    0,    0,    0],\n",
              "       [   2,  282,  333, ...,    2,    3,   20],\n",
              "       [   9,  743,    3, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 223,  182,   15, ...,    0,    0,    0],\n",
              "       [   7,  213,   40, ...,   25,  122,   12],\n",
              "       [   7,  235,    4, ...,   57, 1004,   33]], dtype=int32)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_train_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del val_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'val_texts' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m val_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(nlp\u001b[38;5;241m.\u001b[39mpipe(\u001b[43mval_texts\u001b[49m))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'val_texts' is not defined"
          ]
        }
      ],
      "source": [
        "val_docs = list(nlp.pipe(val_texts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UFbd9YPhZU4"
      },
      "outputs": [
        {
          "ename": "OutOfMemoryError",
          "evalue": "Out of memory allocating 89,630,208 bytes (allocated so far: 11,472,828,928 bytes).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m val_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_texts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m val_texts\n\u001b[1;32m      3\u001b[0m processed_val_texts \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/language.py:1618\u001b[0m, in \u001b[0;36mLanguage.pipe\u001b[0;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[0m\n\u001b[1;32m   1616\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pipe \u001b[38;5;129;01min\u001b[39;00m pipes:\n\u001b[1;32m   1617\u001b[0m         docs \u001b[38;5;241m=\u001b[39m pipe(docs)\n\u001b[0;32m-> 1618\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/util.py:1703\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[1;32m   1694\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1695\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeCallable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1700\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   1701\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1703\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1704\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1705\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1706\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/pipeline/pipe.pyx:55\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/util.py:1703\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[1;32m   1694\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1695\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeCallable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1700\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   1701\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1703\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1704\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1705\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1706\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/pipeline/pipe.pyx:55\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/util.py:1703\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[1;32m   1694\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1695\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeCallable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1700\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   1701\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1703\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1704\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1705\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1706\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/pipeline/trainable_pipe.pyx:73\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/util.py:1650\u001b[0m, in \u001b[0;36mminibatch\u001b[0;34m(items, size)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1649\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[0;32m-> 1650\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1652\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/util.py:1703\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[1;32m   1694\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1695\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeCallable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1700\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   1701\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1703\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1704\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1705\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1706\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/pipeline/trainable_pipe.pyx:79\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/util.py:1722\u001b[0m, in \u001b[0;36mraise_error\u001b[0;34m(proc_name, proc, docs, e)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_error\u001b[39m(proc_name, proc, docs, e):\n\u001b[0;32m-> 1722\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/pipeline/trainable_pipe.pyx:75\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.pipe\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/spacy/pipeline/tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc((\u001b[38;5;241m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[0;32m--> 126\u001b[0m tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/layers/with_array.py:36\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     33\u001b[0m     model: Model[SeqT, SeqT], Xseq: SeqT, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m     34\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[SeqT, Callable]:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Ragged):\n\u001b[0;32m---> 36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], \u001b[43m_ragged_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Padded):\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _padded_forward(model, Xseq, is_train))\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/layers/with_array.py:91\u001b[0m, in \u001b[0;36m_ragged_forward\u001b[0;34m(model, Xr, is_train)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ragged_forward\u001b[39m(\n\u001b[1;32m     88\u001b[0m     model: Model[SeqT, SeqT], Xr: Ragged, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m     89\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Ragged, Callable]:\n\u001b[1;32m     90\u001b[0m     layer: Model[ArrayXd, ArrayXd] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 91\u001b[0m     Y, get_dX \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataXd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYr: Ragged) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Ragged:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Ragged(get_dX(dYr\u001b[38;5;241m.\u001b[39mdataXd), dYr\u001b[38;5;241m.\u001b[39mlengths)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/layers/concatenate.py:65\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(OutT, data_r), backprop\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     data_a, backprop \u001b[38;5;241m=\u001b[39m \u001b[43m_array_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(OutT, data_a), backprop\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/thinc/layers/concatenate.py:73\u001b[0m, in \u001b[0;36m_array_forward\u001b[0;34m(model, X, Ys, callbacks, is_train)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_forward\u001b[39m(\n\u001b[1;32m     70\u001b[0m     model: Model[InT, OutT], X, Ys: List, callbacks, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m     71\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Array2d, Callable]:\n\u001b[1;32m     72\u001b[0m     widths \u001b[38;5;241m=\u001b[39m [Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m Y \u001b[38;5;129;01min\u001b[39;00m Ys]\n\u001b[0;32m---> 73\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mYs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(d_output: Array2d) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m InT:\n\u001b[1;32m     76\u001b[0m         dY \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mas_contig(d_output[:, : widths[\u001b[38;5;241m0\u001b[39m]])\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/cupy/_manipulation/join.py:99\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arrs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     98\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/cupy/_manipulation/join.py:60\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(tup, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m     58\u001b[0m     tup \u001b[38;5;241m=\u001b[39m [m\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tup]\n\u001b[1;32m     59\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32mcupy/_core/_routines_manipulation.pyx:585\u001b[0m, in \u001b[0;36mcupy._core._routines_manipulation.concatenate_method\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/_core/_routines_manipulation.pyx:657\u001b[0m, in \u001b[0;36mcupy._core._routines_manipulation.concatenate_method\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/_core/core.pyx:132\u001b[0m, in \u001b[0;36mcupy._core.core.ndarray.__new__\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/_core/core.pyx:220\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base._init\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/cuda/memory.pyx:740\u001b[0m, in \u001b[0;36mcupy.cuda.memory.alloc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/cuda/memory.pyx:1426\u001b[0m, in \u001b[0;36mcupy.cuda.memory.MemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/cuda/memory.pyx:1447\u001b[0m, in \u001b[0;36mcupy.cuda.memory.MemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/cuda/memory.pyx:1118\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/cuda/memory.pyx:1139\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._malloc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/cuda/memory.pyx:1384\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._try_malloc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mcupy/cuda/memory.pyx:1387\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._try_malloc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: Out of memory allocating 89,630,208 bytes (allocated so far: 11,472,828,928 bytes)."
          ]
        }
      ],
      "source": [
        "processed_val_texts = []\n",
        "for doc in val_docs:\n",
        "    lemmas = [token.lemma_ for token in doc]\n",
        "    processed_val_texts.append(' '.join(lemmas))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZSivwMOYrCA"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "val_seq = get_sequences(tokenizer, processed_val_texts)\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "\n",
        "h = model.fit(\n",
        "    padded_train_seq, train_labels,\n",
        "    validation_data=(val_seq, val_labels),\n",
        "    epochs=20,\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKDxcT0RYrCA"
      },
      "source": [
        "### Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVWJegdLYrCA"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xlqh_jPkYrCA"
      },
      "outputs": [],
      "source": [
        "test_texts = strat_test_set.copy()['text']\n",
        "test_labels = strat_test_set.copy()['class']\n",
        "\n",
        "test_seq = get_sequences(tokenizer, test_texts)\n",
        "test_labels = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cukopLkPYrCA"
      },
      "outputs": [],
      "source": [
        "test_seq, test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBWwAL6KYrCA"
      },
      "outputs": [],
      "source": [
        "_ = model.evaluate(test_seq, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-4q-qsTYrCB"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(test_seq)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "y_pred = np.array(list(map(lambda x: x[1], y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USN-oBMkYrCB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, y_pred).ravel()\n",
        "\n",
        "fpr = fp / (fp + tn)\n",
        "print(f\"False Positive Rate: {fpr:.4f}\")\n",
        "\n",
        "fnr = fn / (fn + tp)\n",
        "print(f\"False Negative Rate: {fnr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6B1GRA5VYrCB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(test_labels, y_pred, normalize=\"true\",\n",
        "                                        values_format=\".0%\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPo_xWTAYrCE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
