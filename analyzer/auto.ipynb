{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "def load_set(directory):\n",
        "    try:\n",
        "        with open(f\"{directory}/texts.pkl\", \"rb\") as fp:\n",
        "            processed_texts = pickle.load(fp)\n",
        "        \n",
        "        with open(f\"{directory}/labels.pkl\", \"rb\") as fp:\n",
        "            labels = pickle.load(fp)\n",
        "    \n",
        "    except:\n",
        "        print(f'{directory} files not found. Please run the preprocess.ipynb before!')\n",
        "    \n",
        "    return processed_texts, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_texts, labels = load_set('train')\n",
        "processed_val_texts, val_labels = load_set('val')\n",
        "processed_test_texts, test_labels = load_set('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "train_ds = Dataset.from_dict({ 'text': processed_texts, 'label': labels })\n",
        "val_ds = Dataset.from_dict({ 'text': processed_val_texts, 'label': val_labels })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert/distilbert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a1952937e154ca9bd4b8eccba78af29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/167304 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20257df8b9e24ca799956c032ec190d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/20914 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_texts = train_ds.map(preprocess_function, batched=True)\n",
        "tokenized_val_texts = val_ds.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-23 18:19:40.022122: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-07-23 18:19:40.028867: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-23 18:19:40.038572: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-23 18:19:40.038586: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-23 18:19:40.045020: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-23 18:19:40.433905: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Creating the Evaluation Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knHAsJ6xYrCA"
      },
      "source": [
        "#### Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "id2label = {0: \"Depressed\", 1: \"Happy\"}\n",
        "label2id = {\"Depressed\": 0, \"Happy\": 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-23 18:19:41.874157: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-07-23 18:19:41.879196: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-07-23 18:19:41.883437: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-07-23 18:19:41.888136: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-07-23 18:19:41.891358: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-07-23 18:19:41.894652: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-07-23 18:19:42.030292: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-07-23 18:19:42.032008: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-07-23 18:19:42.033902: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-07-23 18:19:42.035824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "from transformers import create_optimizer\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 5\n",
        "batches_per_epoch = len(tokenized_texts) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf_train_set = model.prepare_tf_dataset(\n",
        "    tokenized_texts,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_val_set = model.prepare_tf_dataset(\n",
        "    tokenized_val_texts,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fpiP2_ojYrCA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model.compile(optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers.keras_callbacks import KerasMetricCallback\n",
        "\n",
        "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_val_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "callbacks = [metric_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x7ab072b5ab60> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function infer_framework at 0x7ab072b5ab60> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1721773195.712551   31713 service.cc:145] XLA service 0x7aad2d5499f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1721773195.712566   31713 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
            "2024-07-23 18:19:55.715731: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2024-07-23 18:19:55.727840: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8902\n",
            "I0000 00:00:1721773195.762004   31713 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2423/10456 [=====>........................] - ETA: 24:54 - loss: 0.1454"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_train_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_val_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1229\u001b[0m, in \u001b[0;36mTFPreTrainedModel.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mfit)\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1228\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/tf_keras/src/engine/training.py:1804\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1798\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1801\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1802\u001b[0m ):\n\u001b[1;32m   1803\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1804\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1806\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
            "File \u001b[0;32m~/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(x=tf_train_set, validation_data=tf_val_set, epochs=num_epochs, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKDxcT0RYrCA"
      },
      "source": [
        "### Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVWJegdLYrCA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tf_distil_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " distilbert (TFDistilBertMa  multiple                  66362880  \n",
            " inLayer)                                                        \n",
            "                                                                 \n",
            " pre_classifier (Dense)      multiple                  590592    \n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  1538      \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66955010 (255.41 MB)\n",
            "Trainable params: 66955010 (255.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xlqh_jPkYrCA"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd797820b177435eb75f86770d2be8c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/23208 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_ds = Dataset.from_dict({ 'text': processed_test_texts, 'label': test_labels })\n",
        "tokenized_test_texts = test_ds.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenized_test_texts = [tokenizer(text, truncation=True, return_tensors='tf') for text in processed_test_texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logits = [model(**tokenized_test_text).logits for tokenized_test_text in tokenized_test_texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-4q-qsTYrCB"
      },
      "outputs": [],
      "source": [
        "y_pred = [int(tf.math.argmax(logit, axis=-1)[0]) for logit in logits]\n",
        "# y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# y_pred = np.array(list(map(lambda x: x[0], y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USN-oBMkYrCB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False Positive Rate: 0.0275\n",
            "False Negative Rate: 0.0295\n",
            "accuracy_score 0.971\n",
            "precision_score 0.972\n",
            "recall_score 0.970\n",
            "f1_score 0.971\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, y_pred).ravel()\n",
        "\n",
        "fpr = fp / (fp + tn)\n",
        "print(f\"False Positive Rate: {fpr:.4f}\")\n",
        "\n",
        "fnr = fn / (fn + tp)\n",
        "print(f\"False Negative Rate: {fnr:.4f}\")\n",
        "\n",
        "print(f'accuracy_score {accuracy_score(test_labels, y_pred):.3f}')\n",
        "print(f'precision_score {precision_score(test_labels, y_pred):.3f}')\n",
        "print(f'recall_score {recall_score(test_labels, y_pred):.3f}')\n",
        "print(f'f1_score {f1_score(test_labels, y_pred):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6B1GRA5VYrCB"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(test_labels, y_pred, normalize=\"true\",\n",
        "                                        values_format=\".0%\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/peizhe/Documents/Coding/reddit_depression_analysis/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
            "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "with open('./models/hug_clf.pkl', 'wb') as fp:\n",
        "  pickle.dump(model, fp)\n",
        "\n",
        "with open('./models/hug_tok.pkl', 'wb') as fp:\n",
        "  pickle.dump(tokenizer, fp)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
